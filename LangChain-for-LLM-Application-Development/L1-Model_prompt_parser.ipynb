{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2cfafa",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts and Output Parsers\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    " * Direct API calls to OpenAI\n",
    " * API calls through LangChain:\n",
    "   * Prompts\n",
    "   * Models\n",
    "   * Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e51cb3",
   "metadata": {},
   "source": [
    "## Get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb0ce77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f177ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e48f88",
   "metadata": {},
   "source": [
    " 프롬프트는 모델에 입력을 전달하는 방식을 가리킵니다. 그리고 파서는 이러한 모델의 출력을 더 구조화된 형식으로 변환하는 역할을 합니다. 이를 통해 출력 데이터를 다른 곳에서 사용할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50ecf0",
   "metadata": {},
   "source": [
    "LLM(Large Language Model)를 이용해 애플리케이션을 구축하면, 재사용 가능한 여러 가지 모델들이 존재하게 됩니다.   \n",
    "우리는 반복적으로 모델에 프롬프트를 제공하고, 출력값을 파싱합니다.  \n",
    "그래서 LangChain은 이러한 유형의 연산을 쉽게 할 수 있는 추상화 세트를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de1657",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI\n",
    "\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4304836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc12454",
   "metadata": {},
   "source": [
    "GPT 3.5 Turbo 모델이 답변을 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30f61d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I can tell you that the answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e6c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7e6032",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb89660",
   "metadata": {},
   "source": [
    " 이 LLM에게 이 텍스트를 침착하고 존중하는 어조로 미국 영어로 번역하도록 요청하는 것입니다.  \n",
    "  그래서 스타일을 침착하고 존중하는 어조의 미국 영어로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f480992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d34853",
   "metadata": {},
   "source": [
    "이를 실제로 수행하기 위해 앞서 프롬프트 작성법을 조금 보셨다면, f-string을 사용하여 지시문을 명시할 것입니다.  \n",
    " 이 지시문은 triple backticks으로 구분된 텍스트를 스타일인 style으로 번역하라는 내용입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcbe6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d807b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am quite upset that my blender lid came off and caused my smoothie to splatter all over my kitchen walls. Additionally, the warranty does not cover the cost of cleaning up the mess. Would you be able to assist me, please? Thank you kindly.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb1fd5",
   "metadata": {},
   "source": [
    "메세지가 매우 공손한 문장으로 나왔습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702bcc2",
   "metadata": {},
   "source": [
    "이를 더 편리한 방법으로 어떻게 할 수 있는지, LangChain을 사용하여 살펴보겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7312ee3",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "Let's try how we can do the same using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c968414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36317f89",
   "metadata": {},
   "source": [
    "chat OpenAI를 import하겠습니다. 이는 LangChain의 chatGPT API 엔드포인트에 대한 추상화입니다.\n",
    "\n",
    "그래서 chat을 chat OpenAI로 설정하면, 이는 GPT 3.5 Turbo라고도 불리는 chatGPT 모델을 사용하는 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a953fb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41269d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3756dc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59d6e2",
   "metadata": {},
   "source": [
    "애플리케이션을 구축할 때, 저는 종종 temperature 매개변수를 0으로 설정하는 것을 선호합니다. 기본적으로 temperature는 0.7로 설정되어 있습니다.   \n",
    "하지만 여기서는 출력을 조금 덜 무작위하게 만들기 위해 temperature를 0으로 재설정하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7c0d5",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68b6b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817662e",
   "metadata": {},
   "source": [
    "이제 템플릿 문자열을 다음과 같이 정의하겠습니다. 'triple backticks로 구분된 텍스트를 style인 style로 번역하세요.' 그리고 이 텍스트가 들어갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25e4f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6987a",
   "metadata": {},
   "source": [
    "이런 템플릿을 반복적으로 재사용하기 위해 LangChain의 chat prompt template를 import하고, 우리가 방금 위에서 작성한 템플릿 문자열을 사용하여 프롬프트 템플릿을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16ccf5",
   "metadata": {},
   "source": [
    "프롬프트 템플릿에서 원래의 프롬프트를 추출할 수 있으며, 이 프롬프트에는 두 개의 입력 변수인 style과 text가 있다는 것을 인식합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda0b6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9435541f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd639d",
   "metadata": {},
   "source": [
    "it realizes it has two input vairables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abedd317",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f348c3f",
   "metadata": {},
   "source": [
    "이제 스타일을 지정해봅시다. 고객 메시지가 번역될 스타일입니다. 그래서 이걸 customer style라고 부르겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f362e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511cdd2",
   "metadata": {},
   "source": [
    "그리고 여기에 이전과 동일한 고객 이메일이 있습니다.\n",
    "그럼 고객 메시지를 생성하면, 이것은 프롬프트를 생성하고 대형 언어 모델(Large Language Model)에게 전달하여 응답받게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d8bf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95ef9f",
   "metadata": {},
   "source": [
    "this will generate the prompt, and will pass this large language model in a minute to get a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf3a1b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain.schema.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4bf0a5",
   "metadata": {},
   "source": [
    "타입들은 확인하려면,\n",
    "고객 메시지는 실제로 리스트입니다,\n",
    "그리고 리스트의 첫 번째 요소를 살펴보면,\n",
    "생성되어야 할 그 프롬프트와 거의 동일함을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00e3afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d4fe9f",
   "metadata": {},
   "source": [
    "this is more or less that prompt that you would expect this to be creating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3abb3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582b662",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adbc39ad",
   "metadata": {},
   "source": [
    "마지막으로, LLM에게 이 프롬프트를 전달합시다.\n",
    "따라서 chat(우리가 앞서 OpenAI chatGPT 엔드 포인트 참조로 설정한) 을 호출하고,\n",
    "고객 응답 내용을 출력해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46279c81",
   "metadata": {},
   "source": [
    "pass this prompt to the LLM, so I am going to call chat, which we had set earlier, as a reference to the OpneAI chatGPT endpoint,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df13edcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie. To add to my frustration, the warranty doesn't cover the cost of cleaning up my kitchen. Can you please help me out, friend?\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9bc9dd",
   "metadata": {},
   "source": [
    "그러면 이렇게 영어 해적에서 공손한 미국 영어로 번역된 텍스트를 돌려줍니다.\n",
    "\n",
    "물론, 고객 이메일이 다른 언어로 작성된 경우에도 이것을 사용하여 메시지를 영어 사용자가 이해하고 답변할 수 있도록 번역할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16028e0f",
   "metadata": {},
   "source": [
    "if we print out the customer responses content, then it gives you back this text translated form ENG pirate to polite American English."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7742e1",
   "metadata": {},
   "source": [
    "이제 우리의 고객 서비스 담당자가 원래의 언어로 고객에게 답변한다고 가정합시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df2c1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b79186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05bcaf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68588ac",
   "metadata": {},
   "source": [
    "이전에 만들어 둔 프롬프트 템플릿이 있기 때문에, 이제 우리는 그 프롬프트 템플릿을 재사용하고 출력 스타일을 해적 스타일로 지정하며, 텍스트는 서비스 답변으로 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c15ab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy there, me hearty customer! I be sorry to inform ye that the warranty be not coverin' the expenses o' cleaning yer galley, as 'tis yer own fault fer misusin' yer blender by forgettin' to put the lid on afore startin' it. Aye, tough luck! Farewell and may the winds be in yer favor!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c779414",
   "metadata": {},
   "source": [
    "왜 우리가 f-string 대신에 프롬프트 템플릿을 사용하는지 궁금해할 수도 있습니다. 그 답은 복잡한 애플리케이션을 구축함에 있어서, 프롬프트는 종종 길고 상세해질 수 있다는 것입니다.\n",
    "\n",
    "따라서 프롬프트 템플릿은 좋은 프롬프트를 재사용할 수 있도록 도와주는 유용한 추상화입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61c793",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "Let's start with defining how we would like the LLM output to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ba23e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd15df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda86cd",
   "metadata": {},
   "source": [
    "온라인 학습 애플리케이션의 학생 제출물 평가를 위한 긴 프롬프트 예시입니다.\n",
    "LLM(Large Language Model)에게 문제를 먼저 해결하라고 요청한 후, 출력 결과를 특정 형식으로 반환하도록 요청하는 등의 내용이 포함된 매우 긴 프롬프트입니다.\n",
    "\n",
    "LangChain에서 이런 식의 프롬프트를 감싸주면 이런 종류의 프롬프트 재사용하기 쉽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df899949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] output_parser=None partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n', template_format='f-string', validate_template=True), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672f128",
   "metadata": {},
   "source": [
    "또한 나중에 보시겠지만 LangChain은 요약, 질문 응답, SQL 데이터베이스 연결 등 일반적인 작업들에 대한 기본 제공되는 몇 가지 팁들을 제공합니다. 따라서 LangChain의 내장된 팁들을 사용함으로써 자신만의 팁들을 개발할 필요 없이 빠르게 애플리케이션 작동 가능성 확인 가능합니다.\n",
    "\n",
    "LangChain의 팁 라이브러리의 또 다른 측면은 출력 파싱 지원인데, 이는 잠시 후에 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4ee445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gift\": true,\n",
      "    \"delivery_days\": 2,\n",
      "    \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d2b5b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610fe20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5dbe0b",
   "metadata": {},
   "source": [
    "LLM을 이용한 복잡한 애플리케이션 구축 시, 종종 LLM에게 출력을 특정 형식으로 생성하도록 지시합니다. 왼쪽 예시는 LLM을 사용하여 '사슬의 생각' 추론을 수행하는 방법인 React 프레임워크를 사용하는 것입니다. 하지만 기술적 세부 사항에 대해 걱정하지 마세요.   핵심은 '생각'이라는 키워드가 LLM이 생각하는 것입니다.\n",
    "\n",
    "특정 동작을 수행하기 위해 '동작'이라는 키워드를 사용하고, 그 동작에서 배운 것을 보여주기 위해 '관찰'이라는 키워드를 사용하고 있습니다.\n",
    "특정 키워드인 '생각', '동작', '관찰' 등을 사용하여 LLM에게 지시문을 제공하는 프롬프트가 있다면, 이 프롬프트는 파서와 결합될 수 있습니다. 그래서 이런 특정 키워드로 태그된 텍스트를 추출할 수 있게 됩니다. 따라서 입력과 출력 모두에 대해 좋은 추상화를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f382e9b",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01ddfa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e2f91",
   "metadata": {},
   "source": [
    "그럼 이제 LangChain으로 어떻게 출력 파서를 사용하는지 예제로 살펴보겠습니다.\n",
    "이 예제에서는 어떻게 LLM에 JSON 형식으로 출력하도록 요청하고 LangChain으로 그 출력값을 파싱하는지 보여줄 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b4bad6",
   "metadata": {},
   "source": [
    "예제에서 사용할 주요 사례는 제품 리뷰에서 정보를 추출하고 그 정보를 JSON 형식으로 포맷팅 하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac3f59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f7a16",
   "metadata": {},
   "source": [
    "다음으로, 우리는 리뷰에 대한 정보를 추출하고 JSON 형식으로 출력하도록 LLM에게 지시하는 프롬프트를 만들 것입니다. 이 프롬프트에서는 먼저 제품 리뷰를 제공한 후, 그 리뷰에서 특정 정보를 추출하고 그것을 JSON 형식으로 포맷팅하라는 지시문을 LLM에게 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5f564cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9649f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8950f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e090df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26949bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f758ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d089d1",
   "metadata": {},
   "source": [
    "이제 생성된 출력을 파싱하기 위해 LangChain의 출력 파서 기능을 사용할 수 있습니다.\n",
    "\n",
    "LangChain은 또한 내장된 파서들도 제공합니다. 예를 들어, 리스트 파서나 딕셔너리 파서 등이 있습니다. 하지만 여기서는 커스텀 파서인 JSON Parser를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec645d1",
   "metadata": {},
   "source": [
    "이제 생성된 JSON 출력을 파싱하여 Python dict로 변환할 수 있습니다. 결과적으로 얻어진 Python dict는 각 필드와 그에 해당하는 값을 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b71548e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": true,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b6b2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3d15384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': True,\n",
       " 'delivery_days': '2',\n",
       " 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27e98640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f16b812b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d2e64",
   "metadata": {},
   "source": [
    "LangChain의 프롬프트 템플릿과 출력 파서 기능은 복잡한 애플리케이션에서 많은 도움을 줍니다. 특정 입력과 출력 패턴을 재사용하기 위해 프롬프트 템플릿을 사용할 수 있으며, 복잡한 출력 결과를 쉽게 처리하기 위해 출력 파서를 사용할 수 있습니다.\n",
    "\n",
    "결국 LangChain의 목적은 Large Language Model과 상호작용하는 코드 작성 과정을 단순화하고 보다 직관적으로 만드는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424098c",
   "metadata": {},
   "source": [
    " LangChain API를 사용하여 간편하게 LLM(Large Language Model)과 상호작용할 수 있습니다.\n",
    "\n",
    "LangChain API는 프롬프트 템플릿, 출력 파서, 팁 라이브러리 등 다양한 기능을 제공합니다.\n",
    "\n",
    "프롬프트 템플릿: 복잡한 애플리케이션에서 재사용 가능한 프롬프트를 생성하는 데 도움을 줍니다.  \n",
    "출력 파서: LLM의 복잡한 출력을 쉽게 처리하고 파싱할 수 있도록 도와줍니다.  \n",
    "팁 라이브러리: 일반적인 작업들(요약, 질문 응답, 번역 등)에 대해 이미 정의된 프롬프트 템플릿과 출력 파서의 조합을 제공합니다.  \n",
    "또한 LangChain API는 개발자가 자신만의 커스텀 프롬프트와 파서를 만들어 새로운 팁들을 생성하는 것도 가능하게 합니다.  \n",
    " 이런 방식으로 개발자는 복잡하거나 반복적인 코드 없이 간단하게 Large Language Model로부터 가치 있는 결과를 얻어낼 수 있습니다.  \n",
    "\n",
    "따라서 LangChain API는 LLM과 상호작용하는 코드 작성 과정을 단순화하고 보다 직관적으로 만드는 유용한 도구입니다.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
